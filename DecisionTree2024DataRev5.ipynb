{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style = \"color:blue; font-size:24px\">DecisionTree</span>\n",
    "\n",
    "This notebook only focuses on Decision Tree model training.\n",
    "\n",
    "ZeekData24 Attack Profiles \n",
    "\n",
    "Dataset 1: Multiple Attack Types \n",
    "\n",
    "Dataset 2: Multiple Attack Types \n",
    "\n",
    "Dataset 3: Multiple Attack Types \n",
    "\n",
    "Dataset 4: Multiple Attack Types \n",
    "\n",
    "Dataset 5: Multiple Attack Types \n",
    "\n",
    "Datest 6: Benign Data \n",
    "\n",
    "Dataset 7: Benign Data\n",
    "\n",
    "\n",
    "Script combines all datasets and checks to see what unique attacks are contained in the dataframe and splits the data into attack specific dataframes. Each dataframe contains one attack type and all benign data from the original merged dataframe. Decision tree models are then trained for each attack type using both attack and benign data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: All rows of 'label_tactic' before preprocessing:\n",
      "Privilege Escalation\n",
      "Reconnaissance\n",
      "Credential Access\n",
      "Persistence\n",
      "Initial Access\n",
      "Exfiltration\n",
      "Defense Evasion\n",
      "Dataset 2: All rows of 'label_tactic' before preprocessing:\n",
      "Privilege Escalation\n",
      "Reconnaissance\n",
      "Credential Access\n",
      "Persistence\n",
      "Initial Access\n",
      "Exfiltration\n",
      "Defense Evasion\n",
      "Dataset 3: All rows of 'label_tactic' before preprocessing:\n",
      "Privilege Escalation\n",
      "Reconnaissance\n",
      "Credential Access\n",
      "Persistence\n",
      "Initial Access\n",
      "Exfiltration\n",
      "Defense Evasion\n",
      "Dataset 4: All rows of 'label_tactic' before preprocessing:\n",
      "Privilege Escalation\n",
      "Reconnaissance\n",
      "Credential Access\n",
      "Persistence\n",
      "Initial Access\n",
      "Exfiltration\n",
      "Defense Evasion\n",
      "Dataset 5: All rows of 'label_tactic' before preprocessing:\n",
      "Privilege Escalation\n",
      "Reconnaissance\n",
      "Credential Access\n",
      "Persistence\n",
      "Initial Access\n",
      "Exfiltration\n",
      "Defense Evasion\n",
      "Dataset 6: All rows of 'label_tactic' before preprocessing:\n",
      "none\n",
      "Dataset 7: All rows of 'label_tactic' before preprocessing:\n",
      "none\n",
      "Distinct label_tactic values:\n",
      "Privilege Escalation\n",
      "Reconnaissance\n",
      "Credential Access\n",
      "Persistence\n",
      "Initial Access\n",
      "Exfiltration\n",
      "Defense Evasion\n",
      "none\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Privilege Escalation\n",
      "Accuracy: 0.9995077528919517\n",
      "Precision: 0.9995080988140235\n",
      "Recall: 0.9995077528919517\n",
      "F1 Score: 0.9995076373309837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Reconnaissance\n",
      "Accuracy: 0.9975283213182287\n",
      "Precision: 0.9975479068102127\n",
      "Recall: 0.9975283213182287\n",
      "F1 Score: 0.997531176440728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Credential Access\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Persistence\n",
      "Accuracy: 0.9995077528919517\n",
      "Precision: 0.9995080988140235\n",
      "Recall: 0.9995077528919517\n",
      "F1 Score: 0.9995076373309837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Initial Access\n",
      "Accuracy: 0.9993050729673384\n",
      "Precision: 0.9993052114885043\n",
      "Recall: 0.9993050729673384\n",
      "F1 Score: 0.9993049356500434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Exfiltration\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 521:====================================================>  (67 + 3) / 70]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model for label_tactic: Defense Evasion\n",
      "Accuracy: 0.9997539975399754\n",
      "Precision: 0.9997540839475834\n",
      "Recall: 0.9997539975399754\n",
      "F1 Score: 0.9997539686732755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Spark imports\n",
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Python imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Pre-Preprocess Mission Log\") \\\n",
    "    .master(\"spark://192.168.1.2:7077\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.cores\", \"3\") \\\n",
    "    .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.minExecutors\", \"5\") \\\n",
    "    .config(\"spark.dynamicAllocation.maxExecutors\", \"8\") \\\n",
    "    .config(\"spark.executor.instances\", \"5\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Paths containing network data\n",
    "data_paths = [\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-02-25 - 2024-03-03/part-00000-8b838a85-76eb-4896-a0b6-2fc425e828c2-c000.snappy.parquet\",\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-03-03 - 2024-03-10/part-00000-0955ed97-8460-41bd-872a-7375a7f0207e-c000.snappy.parquet\",\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-03-10 - 2024-03-17/part-00000-071774ae-97f3-4f31-9700-8bfcdf41305a-c000.snappy.parquet\",\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-03-17 - 2024-03-24/part-00000-5f556208-a1fc-40a1-9cc2-a4e24c76aeb3-c000.snappy.parquet\",\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-03-24 - 2024-03-31/part-00000-ea3a47a3-0973-4d6b-a3a2-8dd441ee7901-c000.snappy.parquet\",\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-10-27 - 2024-11-03/part-00000-69700ccb-c1c1-4763-beb7-cd0f1a61c268-c000.snappy.parquet\",\n",
    "    \"hdfs://192.168.1.2:9000/datasets-uwf-edu/UWF-TestZeekData24/parquet/2024-11-03 - 2024-11-10/part-00000-f078acc1-ab56-40a6-a6e1-99d780645c57-c000.snappy.parquet\"\n",
    "]\n",
    "\n",
    "# Container to hold the processed DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Counter variable\n",
    "j = 0\n",
    "\n",
    "# Loop through each path, load and process the data\n",
    "for path in data_paths:\n",
    "    # Load each dataset\n",
    "    df = spark.read.parquet(path)\n",
    "   \n",
    "    # Select relevant columns\n",
    "    df = df.select(\"ts\", \"duration\", \"orig_bytes\", \"resp_bytes\", \"orig_ip_bytes\", \"resp_ip_bytes\", \"label_tactic\")\n",
    "   \n",
    "    # Show all rows of attack labels before any preprocessing\n",
    "    print(f\"Dataset {j+1}: All rows of 'label_tactic' before preprocessing:\")\n",
    "    all_label_tactics = df.select(\"label_tactic\").distinct().collect()\n",
    "    for row in all_label_tactics:\n",
    "        print(row['label_tactic'])\n",
    "              \n",
    "    # Handle missing values\n",
    "    df = df.fillna({\n",
    "        \"duration\": 0,\n",
    "        \"orig_bytes\": 0,\n",
    "        \"resp_bytes\": 0,\n",
    "        \"orig_ip_bytes\": 0,\n",
    "        \"resp_ip_bytes\": 0\n",
    "    })\n",
    "    \n",
    "    df_list.append(df)\n",
    "    j += 1\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_df = df_list[0]\n",
    "for df in df_list[1:]:\n",
    "    combined_df = combined_df.union(df)\n",
    "\n",
    "# Get distinct values of label_tactic\n",
    "distinct_label_tactics = combined_df.select(\"label_tactic\").distinct().collect()\n",
    "distinct_label_tactics = [row['label_tactic'] for row in distinct_label_tactics]\n",
    "\n",
    "# Print distinct label_tactic values\n",
    "print(\"Distinct label_tactic values:\")\n",
    "for tactic in distinct_label_tactics:\n",
    "    print(tactic)\n",
    "\n",
    "# Create new DataFrames for each label_tactic\n",
    "dataframes = {}\n",
    "for tactic in distinct_label_tactics:\n",
    "    if tactic != \"none\":\n",
    "        tactic_df = combined_df.filter((F.col(\"label_tactic\") == tactic) | (F.col(\"label_tactic\") == \"none\"))\n",
    "        dataframes[tactic] = tactic_df\n",
    "\n",
    "# Train a decision tree model for each attack DataFrame\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import json\n",
    "\n",
    "models = {}\n",
    "for tactic, df in dataframes.items():\n",
    "    # Prepare the data for training\n",
    "    feature_columns = [\"duration\", \"orig_bytes\", \"resp_bytes\", \"orig_ip_bytes\", \"resp_ip_bytes\"]\n",
    "    assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\", handleInvalid=\"skip\")\n",
    "    df = assembler.transform(df)\n",
    "    \n",
    "    # Convert label_tactic to a numerical label\n",
    "    df = df.withColumn(\"label\", F.when(F.col(\"label_tactic\") == tactic, 1).otherwise(0))\n",
    "    \n",
    "    # Split the data into attack and benign sets\n",
    "    attack_df = df.filter(F.col(\"label\") == 1)\n",
    "    benign_df = df.filter(F.col(\"label\") == 0)\n",
    "    \n",
    "    # Sample benign data to match 70/30 ratio\n",
    "    benign_sample_size = int(attack_df.count() * (70 / 30))\n",
    "    sampling_fraction = min(benign_sample_size / benign_df.count(), 1.0)\n",
    "    benign_sample_df = benign_df.sample(withReplacement=False, fraction=sampling_fraction)\n",
    "    \n",
    "    # Combine attack and sampled benign data\n",
    "    combined_df = attack_df.union(benign_sample_df)\n",
    "    \n",
    "    # Split the combined data into training and test sets\n",
    "    train_df, test_df = combined_df.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    # Train the decision tree model\n",
    "    dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "    model = dt.fit(train_df)\n",
    "    models[tactic] = model\n",
    "    \n",
    "    # Evaluate the model\n",
    "    predictions = model.transform(test_df)\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    \n",
    "    precision = precision_evaluator.evaluate(predictions)\n",
    "    recall = recall_evaluator.evaluate(predictions)\n",
    "    f1_score = f1_evaluator.evaluate(predictions)\n",
    "    \n",
    "    print(f\"\\nModel for label_tactic: {tactic}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
